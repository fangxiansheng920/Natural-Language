# Natural-Language
对于自然语言处理总结
### 自然语言处理编程文档

#### 一、功能概述
自然语言处理功能，包含以下模块：
1. **分词与词性标注**：基于jieba库实现文本分词及词性标注，支持全模式、精确模式、搜索引擎模式。 
2. **词频统计与可视化**：生成词云、饼图、柱状图、折线图等多维度数据可视化。
3. **自定义词典扩展**：支持用户自定义词典提升专业领域分词精度。
4. **实体统计**：按人名（nr）、地名（ns）等词性分类存储。

#### 二、设计思想
1. **模块化设计**：每个功能封装为独立函数，通过主程序调用。
2. **可扩展性**：通过`jieba.load_userdict()`支持用户自定义词典，适应不同领域需求。
3. **数据流控制**：采用“输入-处理-输出”流程，输入支持文件/字符串，输出包含文本文件及可视化图表。

#### 三、核心库及函数
1. **jieba库**:中文分词与词性标注。函数：cut()    
2. **wordcloud库**:词云生成。函数：WordCloud()   
3. **matplotlib库**:数据可视化。函数：pyplot.pie(),pyplot.bar(),pyplot.plot,pyplot.scatter
4. **numpy库**:图像处理与数组操作。函数：np.array()   
---

### 功能完善方案

#### 模块化函数设计
```python
# nlp_core.py
import jieba
import jieba.posseg as pseg
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import networkx as nx
import numpy as np

# 基础处理模块
def load_text(filepath):
    """读取文本文件"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return f.read()

def tokenize(text, user_dict=None):
    """分词功能"""
    if user_dict:
        jieba.load_userdict(user_dict)
    return list(jieba.cut(text))

def get_word_freq(tokens, stopwords_path='stopwords.txt'):
    """词频统计"""
    try:
        stopwords = set(open(stopwords_path, encoding='utf-8').read().split())
    except FileNotFoundError:
        stopwords = set()
    return Counter([w for w in tokens if w not in stopwords and len(w) > 1])

# 词性分析模块
def pos_analysis(text, save_path='pos_result.txt'):
    """词性标注并保存"""
    words = pseg.cut(text)
    result = [f"{word} {flag}" for word, flag in words]
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(result))
    return result

def extract_entities(pos_result, entity_tags):
    """提取特定实体"""
    return [(word.split()[0], word.split()[1]) 
            for word in pos_result 
            if word.split()[1] in entity_tags]

# 可视化模块
def generate_wordcloud(text, save_path='wordcloud.png'):
    """生成词云"""
    wc = WordCloud(font_path='msyh.ttc', width=800, height=600)
    wc.generate(text)
    wc.to_file(save_path)
    return save_path

def plot_freq_chart(counter, top_n=10, chart_type='bar', save_path='chart.png'):
    """生成频率图表"""
    plt.switch_backend('Agg')  # 解决GUI中的线程问题
    items = counter.most_common(top_n)
    words, counts = zip(*items)
    
    plt.figure(figsize=(12, 6))
    if chart_type == 'bar':
        plt.bar(words, counts)
    elif chart_type == 'pie':
        plt.pie(counts, labels=words, autopct='%1.1f%%')
    
    plt.title('词频分布图')
    plt.savefig(save_path)
    plt.close()
    return save_path

# 自定义词典管理
def manage_custom_dict(word, action='add', dict_path='user_dict.txt'):
    """管理用户词典"""
    if action == 'add':
        with open(dict_path, 'a', encoding='utf-8') as f:
            f.write(f"\n{word}")
    elif action == 'remove':
        lines = [line for line in open(dict_path, encoding='utf-8') 
                if line.strip() != word]
        with open(dict_path, 'w', encoding='utf-8') as f:
            f.writelines(lines)
```

---

### 界面设计方案

#### 方案选择：Tkinter
采用Python内置Tkinter库实现桌面GUI，优点包括：
1. **零依赖**：无需额外安装框架。
2. **功能完备**：支持文件选择、参数配置、结果展示控件。

#### 核心组件设计
```python
# main_gui.py
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from PIL import ImageTk, Image
import nlp_core as nlp

class NLPApp:
    def __init__(self, master):
        self.master = master
        master.title("自然语言处理系统 v1.0")
        master.geometry("1000x700")

        # 界面布局
        self.create_file_frame()
        self.create_analysis_frame()
        self.create_visual_frame()
        self.create_output_frame()

    def create_file_frame(self):
        """文件选择区域"""
        frame = ttk.LabelFrame(self.master, text="文件管理")
        frame.pack(fill='x', padx=10, pady=5)

        self.filepath = tk.StringVar()
        ttk.Entry(frame, textvariable=self.filepath, width=50).grid(row=0, column=0, padx=5)
        ttk.Button(frame, text="选择文件", command=self.load_file).grid(row=0, column=1)
        ttk.Button(frame, text="加载自定义词典", command=self.load_dict).grid(row=0, column=2)

    def create_analysis_frame(self):
        """分析功能区域"""
        frame = ttk.LabelFrame(self.master, text="分析功能")
        frame.pack(fill='x', padx=10, pady=5)

        ttk.Button(frame, text="执行分词", command=self.run_tokenize).grid(row=0, column=0, padx=5)
        ttk.Button(frame, text="词频统计", command=self.run_word_freq).grid(row=0, column=1)
        ttk.Button(frame, text="词性分析", command=self.run_pos_analysis).grid(row=0, column=2)
        ttk.Button(frame, text="实体抽取", command=self.run_entity_extract).grid(row=0, column=3)

    def create_visual_frame(self):
        """可视化区域"""
        frame = ttk.LabelFrame(self.master, text="可视化")
        frame.pack(fill='both', expand=True, padx=10, pady=5)

        self.canvas_frame = ttk.Frame(frame)
        self.canvas_frame.pack(side='left', fill='both', expand=True)

        self.img_label = ttk.Label(self.canvas_frame)
        self.img_label.pack()

        control_frame = ttk.Frame(frame)
        control_frame.pack(side='right', padx=10)
        ttk.Button(control_frame, text="生成词云", command=self.show_wordcloud).pack(pady=5)
        ttk.Button(control_frame, text="柱状图", 
                 command=lambda: self.show_chart('bar')).pack(pady=5)
        ttk.Button(control_frame, text="饼状图",
                 command=lambda: self.show_chart('pie')).pack(pady=5)

    def create_output_frame(self):
        """结果显示区域"""
        frame = ttk.LabelFrame(self.master, text="分析结果")
        frame.pack(fill='both', expand=True, padx=10, pady=5)

        self.result_text = tk.Text(frame, wrap='word')
        scrollbar = ttk.Scrollbar(frame, command=self.result_text.yview)
        self.result_text.configure(yscrollcommand=scrollbar.set)
        
        self.result_text.pack(side='left', fill='both', expand=True)
        scrollbar.pack(side='right', fill='y')

    # 核心功能方法
    def load_file(self):
        """加载文本文件"""
        path = filedialog.askopenfilename(filetypes=[("Text files", "*.txt")])
        if path:
            self.filepath.set(path)
            self.raw_text = nlp.load_text(path)
            self.result_text.delete(1.0, tk.END)
            self.result_text.insert(tk.END, "文件加载成功！")

    def load_dict(self):
        """加载自定义词典"""
        path = filedialog.askopenfilename(filetypes=[("Dict files", "*.txt")])
        if path:
            jieba.load_userdict(path)
            messagebox.showinfo("提示", "自定义词典加载成功！")

    def run_tokenize(self):
        """执行分词"""
        if not hasattr(self, 'raw_text'):
            messagebox.showerror("错误", "请先选择文件！")
            return
        self.tokens = nlp.tokenize(self.raw_text)
        self.result_text.delete(1.0, tk.END)
        self.result_text.insert(tk.END, "分词结果：\n" + "/".join(self.tokens[:200]) + "...")

    def show_chart(self, chart_type):
        """显示图表"""
        if not hasattr(self, 'word_freq'):
            messagebox.showerror("错误", "请先进行词频统计！")
            return
        img_path = nlp.plot_freq_chart(self.word_freq, chart_type=chart_type)
        self.display_image(img_path)

    def display_image(self, img_path):
        """显示图片"""
        img = Image.open(img_path)
        img = img.resize((600, 400), Image.Resampling.LANCZOS)
        photo = ImageTk.PhotoImage(img)
        self.img_label.configure(image=photo)
        self.img_label.image = photo  # 保持引用

# 启动程序
if __name__ == "__main__":
    root = tk.Tk()
    app = NLPApp(root)
    root.mainloop()
```

---


